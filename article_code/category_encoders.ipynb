{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import category_encoders as ce\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import hashlib\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nEncoders can be divided into 4 different groups as seen in \"encoders.png\".\\nSplits refer to:\\n\\n- Supervised/Unsupervised: when the encoding is based solely on the\\ncategorical column, then it’s unsupervised. Otherwise, if the encoding is\\nbased on some function of the original column and a second (numeric) column,\\nthen it’s supervised.\\n\\n- Output dimension: the encoding of a categorical column may produce one\\nnumeric column (output dimension = 1) or many numeric columns\\n(output dimension > 1).\\n\\n- Mapping: if each level has always the same output — whether a scalar\\n(e.g. OrdinalEncoder) or an array (e.g. OneHotEncoder)— then the mapping\\nis unique. On the contrary, if the same level is “allowed” to\\nhave different possible outputs, then the mapping is not unique.\\n\\nBelow is the overview of the encodings:\\n'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Encoders can be divided into 4 different groups as seen in \"encoders.png\".\n",
    "Splits refer to:\n",
    "\n",
    "- Supervised/Unsupervised: when the encoding is based solely on the\n",
    "categorical column, then it’s unsupervised. Otherwise, if the encoding is\n",
    "based on some function of the original column and a second (numeric) column,\n",
    "then it’s supervised.\n",
    "\n",
    "- Output dimension: the encoding of a categorical column may produce one\n",
    "numeric column (output dimension = 1) or many numeric columns\n",
    "(output dimension > 1).\n",
    "\n",
    "- Mapping: if each level has always the same output — whether a scalar\n",
    "(e.g. OrdinalEncoder) or an array (e.g. OneHotEncoder)— then the mapping\n",
    "is unique. On the contrary, if the same level is “allowed” to\n",
    "have different possible outputs, then the mapping is not unique.\n",
    "\n",
    "Below is the overview of the encodings:\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# first let's create the list to encode:\n",
    "x = pd.Series(['2_Bachelors', '1_High-School', '4_PhD', '3_Masters', '1_High-School', '2_Bachelors'], name = 'x')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "               x  OrdinalEncoding\n0    2_Bachelors                2\n1  1_High-School                1\n2          4_PhD                4\n3      3_Masters                3\n4  1_High-School                1\n5    2_Bachelors                2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>OrdinalEncoding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4_PhD</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3_Masters</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1_High-School</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Ordinal Encoder\n",
    "# Used as a representation of convenience, used often to save memory,\n",
    "# or as intermediate step for other types of encoding.\n",
    "sorted_x = sorted(set(x))\n",
    "ordinal_encoding = x.replace(dict(zip(sorted_x, range(1, len(sorted_x) + 1))))\n",
    "ordinal_encoding.name = 'OrdinalEncoding'\n",
    "show = pd.concat([x, ordinal_encoding], axis = 1)\n",
    "show"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "               x  CountEncoding\n0    2_Bachelors              2\n1  1_High-School              2\n2          4_PhD              1\n3      3_Masters              1\n4  1_High-School              2\n5    2_Bachelors              2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>CountEncoding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4_PhD</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3_Masters</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1_High-School</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. CountEncoder\n",
    "# This encoding may be useful as an indicator of the “credibility” of each level.\n",
    "# For instance, a machine learning algorithm may automatically decide to \n",
    "# take into account the information brought by the level only if its count \n",
    "# is above some threshold.\n",
    "count_encoding = x.replace(x.value_counts().to_dict())\n",
    "count_encoding.name = 'CountEncoding'\n",
    "show = pd.concat([x, count_encoding], axis = 1)\n",
    "show\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "               x OrdinalEncoding OneHotEncoding                            \n                                  1_High-School 2_Bachelors 3_Masters 4_PhD\n0    2_Bachelors               2              0           1         0     0\n1  1_High-School               1              1           0         0     0\n2          4_PhD               4              0           0         0     1\n3      3_Masters               3              0           0         1     0\n4  1_High-School               1              1           0         0     0\n5    2_Bachelors               2              0           1         0     0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>x</th>\n      <th>OrdinalEncoding</th>\n      <th colspan=\"4\" halign=\"left\">OneHotEncoding</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>1_High-School</th>\n      <th>2_Bachelors</th>\n      <th>3_Masters</th>\n      <th>4_PhD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4_PhD</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3_Masters</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1_High-School</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. OneHotEncoder\n",
    "# The encoding algorithm for excellence (and the most used).\n",
    "# Each level is mapped to a dummy column (i.e. a column of 0/1),\n",
    "# indicating whether that level is carried by that row\n",
    "ordinal_encoding = x.replace(dict(zip(sorted(set(x)), range(1, len(sorted(set(x))) + 1))))\n",
    "one_hot_encoding = ordinal_encoding.apply(\n",
    "    lambda oe: pd.Series(np.diag(np.ones(len(set(x))))[oe - 1].astype(int))\n",
    ")\n",
    "one_hot_encoding.columns = sorted(set(x))\n",
    "show = pd.concat([x, ordinal_encoding, one_hot_encoding], axis = 1)\n",
    "show.columns = [['x', 'OrdinalEncoding'] + ['OneHotEncoding'] * len(set(x)),\n",
    "                [''] * 2 + list(one_hot_encoding.columns)]\n",
    "show"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "               x OrdinalEncoding   SumEncoding                      \n                                 1_High-School 2_Bachelors 3_Masters\n0    2_Bachelors               2             0           1         0\n1  1_High-School               1             1           0         0\n2          4_PhD               4            -1          -1        -1\n3      3_Masters               3             0           0         1\n4  1_High-School               1             1           0         0\n5    2_Bachelors               2             0           1         0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>x</th>\n      <th>OrdinalEncoding</th>\n      <th colspan=\"3\" halign=\"left\">SumEncoding</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>1_High-School</th>\n      <th>2_Bachelors</th>\n      <th>3_Masters</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4_PhD</td>\n      <td>4</td>\n      <td>-1</td>\n      <td>-1</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3_Masters</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1_High-School</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. SumEncoder\n",
    "\n",
    "ordinal_encoding = x.replace(dict(zip(sorted(set(x)), range(1, len(sorted(set(x))) + 1))))\n",
    "one_hot_encoding = ordinal_encoding.apply(lambda e: pd.Series(np.diag(np.ones(len(set(x))))[e - 1].astype(int)))\n",
    "\n",
    "sum_encoding = one_hot_encoding.iloc[:, :-1].apply(\n",
    "    lambda row: row if row.sum() == 1 else row.replace(0, -1), axis = 1\n",
    ")\n",
    "\n",
    "sum_encoding.columns = sorted(set(x))[:-1]\n",
    "show = pd.concat([x, ordinal_encoding, sum_encoding], axis = 1)\n",
    "show.columns = [['x', 'OrdinalEncoding'] + ['SumEncoding'] * (len(set(x)) - 1), [''] * 2 + sorted(set(x))[:-1]]\n",
    "show\n",
    "\n",
    "# SumEncoder (as the next 3 encoders) belongs to a class called\n",
    "# “contrast encodings”. These encodings are designed to have a specific\n",
    "# behaviour when used in regression problems. In other words, you use one\n",
    "# of these encodings if you want the regression coefficients to have some\n",
    "# specific properties.\n",
    "# In particular, SumEncoder is used when you want the regression coefficients\n",
    "# to have zero-sum\n",
    "# The intercept of performed OLS will be equal to the mean of y."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "               x OrdinalEncoding BackwardDifferenceEncoding                \n                                                2_Bachelors 3_Masters 4_PhD\n0    2_Bachelors               2                       0.25      -0.5 -0.25\n1  1_High-School               1                      -0.75      -0.5 -0.25\n2          4_PhD               4                       0.25       0.5  0.75\n3      3_Masters               3                       0.25       0.5 -0.25\n4  1_High-School               1                      -0.75      -0.5 -0.25\n5    2_Bachelors               2                       0.25      -0.5 -0.25",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>x</th>\n      <th>OrdinalEncoding</th>\n      <th colspan=\"3\" halign=\"left\">BackwardDifferenceEncoding</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>2_Bachelors</th>\n      <th>3_Masters</th>\n      <th>4_PhD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n      <td>0.25</td>\n      <td>-0.5</td>\n      <td>-0.25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>1</td>\n      <td>-0.75</td>\n      <td>-0.5</td>\n      <td>-0.25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4_PhD</td>\n      <td>4</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3_Masters</td>\n      <td>3</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>-0.25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1_High-School</td>\n      <td>1</td>\n      <td>-0.75</td>\n      <td>-0.5</td>\n      <td>-0.25</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n      <td>0.25</td>\n      <td>-0.5</td>\n      <td>-0.25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Backward Difference Encoder\n",
    "ordinal_encoding = x.replace(dict(zip(sorted(set(x)), range(1, len(sorted(set(x))) + 1))))\n",
    "\n",
    "backward_difference_encoding = ordinal_encoding.apply(\n",
    "    lambda oe: pd.Series(\n",
    "        [i / len(set(x)) for i in range(1, oe)] +\n",
    "        [- i / len(set(x)) for i in range(len(set(x)) - oe, 0, -1)]\n",
    "    )\n",
    ")\n",
    "\n",
    "backward_difference_encoding.columns = sorted(set(x))[1:]\n",
    "show = pd.concat([x, ordinal_encoding, backward_difference_encoding], axis = 1)\n",
    "show.columns = [['x', 'OrdinalEncoding'] + ['BackwardDifferenceEncoding'] * len(sorted(set(x))[1:]), [''] * 2 + sorted(set(x))[1:]]\n",
    "show"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "                           x BackwardDifferenceEncoding                   y  \\\n                                            2_Bachelors 3_Masters 4_PhD       \nintercept                                                                     \n1_High-School  1_High-School                      -0.75      -0.5 -0.25  35   \n2_Bachelors      2_Bachelors                       0.25      -0.5 -0.25  45   \n3_Masters          3_Masters                       0.25       0.5 -0.25  52   \n4_PhD                  4_PhD                       0.25       0.5  0.75  68   \n\n              ols_coefs  \n                         \nintercept            50  \n1_High-School            \n2_Bachelors          10  \n3_Masters             7  \n4_PhD                16  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>x</th>\n      <th colspan=\"3\" halign=\"left\">BackwardDifferenceEncoding</th>\n      <th>y</th>\n      <th>ols_coefs</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>2_Bachelors</th>\n      <th>3_Masters</th>\n      <th>4_PhD</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>intercept</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>1_High-School</th>\n      <td>1_High-School</td>\n      <td>-0.75</td>\n      <td>-0.5</td>\n      <td>-0.25</td>\n      <td>35</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2_Bachelors</th>\n      <td>2_Bachelors</td>\n      <td>0.25</td>\n      <td>-0.5</td>\n      <td>-0.25</td>\n      <td>45</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3_Masters</th>\n      <td>3_Masters</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>-0.25</td>\n      <td>52</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>4_PhD</th>\n      <td>4_PhD</td>\n      <td>0.25</td>\n      <td>0.5</td>\n      <td>0.75</td>\n      <td>68</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This encoder is useful for ordinal variables,\n",
    "# i.e. variables whose levels can be ordered in a meaningful way.\n",
    "# BackwardDifferenceEncoder is designed to compare adjacent levels.\n",
    "# Suppose you have an ordinable variable (e.g. education level)\n",
    "# and you want to know how it is related to a numeric variable (e.g. income).\n",
    "# It may be interesting to compare each couple of consecutive levels\n",
    "# (e.g. bachelors vs. high-school, masters vs. bachelors) with respect to\n",
    "# the target variable. Let’s see an example:\n",
    "\n",
    "x = pd.Series(['1_High-School', '2_Bachelors', '3_Masters', '4_PhD'], name = 'x')\n",
    "x.index = x.to_list()\n",
    "y = pd.Series([35, 45, 52, 68], index = x.index, name = 'y')\n",
    "\n",
    "backward_difference_encoding = ce.BackwardDifferenceEncoder().fit_transform(X = x.sort_values()).drop('intercept', axis = 1)\n",
    "backward_difference_encoding.columns = x.to_list()[1:]\n",
    "\n",
    "ols_coefs = sm.OLS(y, pd.concat([pd.Series(1, index = backward_difference_encoding.index, name = 'intercept'), backward_difference_encoding], axis = 1)).fit().params\n",
    "\n",
    "show = pd.concat([x, backward_difference_encoding, y, ols_coefs], axis = 1).loc[['intercept'] + x.to_list()]\n",
    "show.columns = [['x'] + ['BackwardDifferenceEncoding'] * backward_difference_encoding.shape[1] + ['y', 'ols_coefs'], [''] + list(backward_difference_encoding.columns) + [''] * 2]\n",
    "show.fillna('')\n",
    "# The intercept coincides with the mean of y.\n",
    "# The coefficient of Bachelors is 10, because y of Bachelors is 10 higher\n",
    "# than High-School, Masters’ coefficient equals 7 because y of Masters\n",
    "# is 7 higher than Bachelors and so on."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "               x OrdinalEncoding HelmertEncoding                \n                                     2_Bachelors 3_Masters 4_PhD\n0    2_Bachelors               2             0.5     -0.33 -0.25\n1  1_High-School               1            -0.5     -0.33 -0.25\n2          4_PhD               4             0.0      0.00  0.75\n3      3_Masters               3             0.0      0.67 -0.25\n4  1_High-School               1            -0.5     -0.33 -0.25\n5    2_Bachelors               2             0.5     -0.33 -0.25",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>x</th>\n      <th>OrdinalEncoding</th>\n      <th colspan=\"3\" halign=\"left\">HelmertEncoding</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>2_Bachelors</th>\n      <th>3_Masters</th>\n      <th>4_PhD</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n      <td>0.5</td>\n      <td>-0.33</td>\n      <td>-0.25</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>1</td>\n      <td>-0.5</td>\n      <td>-0.33</td>\n      <td>-0.25</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4_PhD</td>\n      <td>4</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.75</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3_Masters</td>\n      <td>3</td>\n      <td>0.0</td>\n      <td>0.67</td>\n      <td>-0.25</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1_High-School</td>\n      <td>1</td>\n      <td>-0.5</td>\n      <td>-0.33</td>\n      <td>-0.25</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n      <td>0.5</td>\n      <td>-0.33</td>\n      <td>-0.25</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Helmert Encoder\n",
    "# contrast encoding\n",
    "\n",
    "x = pd.Series(['2_Bachelors', '1_High-School', '4_PhD', '3_Masters', '1_High-School', '2_Bachelors'], name = 'x')\n",
    "# this implementation is similar to https://stats.idre.ucla.edu/r/library/r-library-contrast-coding-systems-for-categorical-variables/\n",
    "ordinal_encoding = x.replace(dict(zip(sorted(set(x)), range(1, len(sorted(set(x))) + 1))))\n",
    "\n",
    "helmert_encoding = ordinal_encoding.apply(\n",
    "    lambda oe: pd.Series(\n",
    "        [0] * (oe - 2) +\n",
    "        ([oe - 1] if oe > 1 else []) + [-1] * (len(set(x)) - oe)\n",
    "    )\n",
    ").div(pd.Series(range(2, len(set(x)) + 1)))\n",
    "\n",
    "helmert_encoding.columns = sorted(set(x))[1:]\n",
    "show = pd.concat([x, ordinal_encoding, helmert_encoding], axis = 1)\n",
    "show.columns = [['x', 'OrdinalEncoding'] + ['HelmertEncoding'] * helmert_encoding.shape[1], [''] * 2 + sorted(set(x))[1:]]\n",
    "show.round(2)\n",
    "\n",
    "# HelmertEncoder is very similar to BackwardDifferenceEncoder,\n",
    "# but instead of being compared just to the previous one,\n",
    "# each level is compared with all the previous levels.\n",
    "# In this case, the outcome of category_encoders has a different implementation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "                           x HelmertEncoding                   y ols_coefs\n                                 2_Bachelors 3_Masters 4_PhD              \nintercept                                                               50\n1_High-School  1_High-School            -0.5 -0.333333 -0.25  35          \n2_Bachelors      2_Bachelors             0.5 -0.333333 -0.25  45        10\n3_Masters          3_Masters               0  0.666667 -0.25  52        12\n4_PhD                  4_PhD               0         0  0.75  68        24",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>x</th>\n      <th colspan=\"3\" halign=\"left\">HelmertEncoding</th>\n      <th>y</th>\n      <th>ols_coefs</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th>2_Bachelors</th>\n      <th>3_Masters</th>\n      <th>4_PhD</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>intercept</th>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td>50</td>\n    </tr>\n    <tr>\n      <th>1_High-School</th>\n      <td>1_High-School</td>\n      <td>-0.5</td>\n      <td>-0.333333</td>\n      <td>-0.25</td>\n      <td>35</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2_Bachelors</th>\n      <td>2_Bachelors</td>\n      <td>0.5</td>\n      <td>-0.333333</td>\n      <td>-0.25</td>\n      <td>45</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>3_Masters</th>\n      <td>3_Masters</td>\n      <td>0</td>\n      <td>0.666667</td>\n      <td>-0.25</td>\n      <td>52</td>\n      <td>12</td>\n    </tr>\n    <tr>\n      <th>4_PhD</th>\n      <td>4_PhD</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.75</td>\n      <td>68</td>\n      <td>24</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let’s see what we would get from a OLS model:\n",
    "x = pd.Series(['1_High-School', '2_Bachelors', '3_Masters', '4_PhD'], name = 'x')\n",
    "x.index = x.to_list()\n",
    "y = pd.Series([35, 45, 52, 68], index = x.index, name = 'y')\n",
    "\n",
    "ordinal_encoding = x.replace(dict(zip(sorted(set(x)), range(1, len(sorted(set(x))) + 1))))\n",
    "helmert_encoding = ordinal_encoding.apply(\n",
    "    lambda oe: pd.Series([0] * (oe - 2) + ([oe - 1] if oe > 1 else []) + [-1] * (len(set(x)) - oe))\n",
    ").div(pd.Series(range(2,len(set(x)) + 1)))\n",
    "helmert_encoding.columns = x.to_list()[1:]\n",
    "\n",
    "ols_coefs = sm.OLS(y, pd.concat([pd.Series(1, index = helmert_encoding.index, name = 'intercept'), helmert_encoding], axis = 1)).fit().params\n",
    "\n",
    "show = pd.concat([x, helmert_encoding, y, ols_coefs], axis = 1).loc[['intercept'] + x.to_list()]\n",
    "show.columns = [['x'] + ['HelmertEncoding'] * helmert_encoding.shape[1] + ['y', 'ols_coefs'], [''] + list(helmert_encoding.columns) + [''] * 2]\n",
    "show.fillna('')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# PhD’s coefficient is 24, because PhD is 24 higher than the\n",
    "# mean of the previous levels 68-((35+45+52)/3)=24.\n",
    "# The same reasoning applies to all the levels."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "               x OrdinalEncoding PolynomialEncoding                \n                                            degree1 degree2 degree3\n0    2_Bachelors               2             -0.224    -0.5   0.671\n1  1_High-School               1             -0.671     0.5  -0.224\n2          4_PhD               4              0.671     0.5   0.224\n3      3_Masters               3              0.224    -0.5  -0.671\n4  1_High-School               1             -0.671     0.5  -0.224\n5    2_Bachelors               2             -0.224    -0.5   0.671",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>x</th>\n      <th>OrdinalEncoding</th>\n      <th colspan=\"3\" halign=\"left\">PolynomialEncoding</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>degree1</th>\n      <th>degree2</th>\n      <th>degree3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n      <td>-0.224</td>\n      <td>-0.5</td>\n      <td>0.671</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>1</td>\n      <td>-0.671</td>\n      <td>0.5</td>\n      <td>-0.224</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4_PhD</td>\n      <td>4</td>\n      <td>0.671</td>\n      <td>0.5</td>\n      <td>0.224</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3_Masters</td>\n      <td>3</td>\n      <td>0.224</td>\n      <td>-0.5</td>\n      <td>-0.671</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1_High-School</td>\n      <td>1</td>\n      <td>-0.671</td>\n      <td>0.5</td>\n      <td>-0.224</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n      <td>-0.224</td>\n      <td>-0.5</td>\n      <td>0.671</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 7. PolynomialEncoder\n",
    "# contrast encoding\n",
    "# As its name suggests, PolynomialEncoder is designed to quantify linear,\n",
    "# quadratic and cubic behaviors of the target variable with respect to\n",
    "# the categorical variable\n",
    "\n",
    "x = pd.Series(['2_Bachelors', '1_High-School', '4_PhD', '3_Masters', '1_High-School', '2_Bachelors'], name = 'x')\n",
    "\n",
    "def do_polynomial_encoding(order):\n",
    "    # https://github.com/pydata/patsy/blob/master/patsy/contrasts.py\n",
    "    n = len(set(x))\n",
    "    scores = np.arange(n)\n",
    "    scores = np.asarray(scores, dtype=float)\n",
    "    scores -= scores.mean()\n",
    "    raw_poly = scores.reshape((-1, 1)) ** np.arange(n).reshape((1, -1))\n",
    "    q, r = np.linalg.qr(raw_poly)\n",
    "    q *= np.sign(np.diag(r))\n",
    "    q /= np.sqrt(np.sum(q ** 2, axis=1))\n",
    "    # q[:, 0] = 1\n",
    "    q = q[:, 1:]\n",
    "    return q[order - 1]\n",
    "\n",
    "ordinal_encoding = x.replace(dict(zip(sorted(set(x)), range(1, len(sorted(set(x))) + 1))))\n",
    "polynomial_encoding = ordinal_encoding.apply(lambda oe: pd.Series(do_polynomial_encoding(oe)))\n",
    "\n",
    "# ensure that our output coincides with the one from category_encoders\n",
    "assert polynomial_encoding.eq(ce.PolynomialEncoder().fit_transform(X = x.sort_values()).drop('intercept', axis = 1).rename(lambda c: int(c[2:]), axis='columns')).all().all()\n",
    "\n",
    "polynomial_encoding.columns = ['degree' + str(i) for i in range(1, polynomial_encoding.shape[1] + 1)]\n",
    "show = pd.concat([x, ordinal_encoding, polynomial_encoding], axis = 1)\n",
    "show.columns = [['x', 'OrdinalEncoding'] + ['PolynomialEncoding'] * polynomial_encoding.shape[1],\n",
    "                [''] * 2 + list(polynomial_encoding.columns)]\n",
    "show.round(3)\n",
    "\n",
    "# This is based on the assumption that the underlying categorical variable\n",
    "# has levels that are not only ordinable, but also equally spaced.\n",
    "# For this reason, I would suggest to use it with care,\n",
    "# only when you are sure that the assumption is reasonable."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "               x OrdinalEncoding binary_base BinaryEncoding          \n                                                       dim3 dim2 dim1\n0    2_Bachelors               2         010              0    1    0\n1  1_High-School               1         001              0    0    1\n2          4_PhD               4         100              1    0    0\n3      3_Masters               3         011              0    1    1\n4  1_High-School               1         001              0    0    1\n5    2_Bachelors               2         010              0    1    0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>x</th>\n      <th>OrdinalEncoding</th>\n      <th>binary_base</th>\n      <th colspan=\"3\" halign=\"left\">BinaryEncoding</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>dim3</th>\n      <th>dim2</th>\n      <th>dim1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n      <td>010</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>1</td>\n      <td>001</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4_PhD</td>\n      <td>4</td>\n      <td>100</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3_Masters</td>\n      <td>3</td>\n      <td>011</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1_High-School</td>\n      <td>1</td>\n      <td>001</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n      <td>010</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Binary Encoder\n",
    "# BinaryEncoder is basically the same of OrdinalEncoder,\n",
    "# the only difference is that the integers are converted to binary numbers,\n",
    "# then every positional digit is one-hot encoded\n",
    "x = pd.Series(['2_Bachelors', '1_High-School', '4_PhD', '3_Masters', '1_High-School', '2_Bachelors'], name = 'x')\n",
    "ordinal_encoding = x.replace(dict(zip(sorted(set(x)), range(1, len(sorted(set(x))) + 1))))\n",
    "\n",
    "binary_base = ordinal_encoding.apply(\n",
    "    lambda oe: str(bin(oe))[2:].zfill(len(bin(len(set(x)))) - 2)\n",
    ")\n",
    "binary_encoding = binary_base.apply(lambda bb: pd.Series(list(bb))).astype(int)\n",
    "\n",
    "# ensure that our output coincides with the one from category_encoders\n",
    "assert binary_encoding.eq(ce.BinaryEncoder().fit_transform(X = x.sort_values()).rename(lambda c: int(c[2:]), axis='columns')).all().all()\n",
    "\n",
    "binary_encoding.columns = ['dim' + str(i) for i in range(binary_encoding.shape[1], 0, -1)]\n",
    "show = pd.concat([x, ordinal_encoding, binary_base, binary_encoding], axis = 1)\n",
    "show.columns = [\n",
    "    ['x', 'OrdinalEncoding', 'binary_base'] + ['BinaryEncoding'] * binary_encoding.shape[1],\n",
    "    [''] * 3 + list(binary_encoding.columns)\n",
    "]\n",
    "show\n",
    "# The output consists of dummy columns, as happens for the OneHotEncoder,\n",
    "# but it leads to a dimensionality reduction with respect to one-hot.\n",
    "# Honestly, I don’t know any practical application of this type of encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "               x ordinal_encoding base_3 BaseNEncoding     \n                                                  dim2 dim1\n0    2_Bachelors                2      2             0    2\n1  1_High-School                1      1             0    1\n2          4_PhD                4     11             1    1\n3      3_Masters                3     10             1    0\n4  1_High-School                1      1             0    1\n5    2_Bachelors                2      2             0    2",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>x</th>\n      <th>ordinal_encoding</th>\n      <th>base_3</th>\n      <th colspan=\"2\" halign=\"left\">BaseNEncoding</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>dim2</th>\n      <th>dim1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4_PhD</td>\n      <td>4</td>\n      <td>11</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3_Masters</td>\n      <td>3</td>\n      <td>10</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1_High-School</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>2</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 9. Base N Encoder\n",
    "# BaseNEncoder is simply a generalization of the BinaryEncoder.\n",
    "# In fact, in BinaryEncoder, the numbers are in base 2, whereas in BaseNEncoder,\n",
    "# numbers are in base n, with n greater than 1\n",
    "x = pd.Series(['2_Bachelors', '1_High-School', '4_PhD', '3_Masters', '1_High-School', '2_Bachelors'], name = 'x')\n",
    "ordinal_encoding = x.replace(dict(zip(sorted(set(x)), range(1, len(sorted(set(x))) + 1))))\n",
    "def int2base(n, base):\n",
    "    # return representation of int n in base base\n",
    "    out = ''\n",
    "    while n:\n",
    "        out += str(int(n % base))\n",
    "        n //= base\n",
    "    return out[::-1]\n",
    "\n",
    "base = 3\n",
    "base_n = ordinal_encoding.apply(lambda oe: int2base(n=oe, base=base))\n",
    "base_n_encoding = base_n.apply(\n",
    "    lambda bn: pd.Series(list(bn.zfill(base_n.apply(len).max())))\n",
    ").astype(int)\n",
    "\n",
    "# ensure that our output coincides with the one from category_encoders\n",
    "assert base_n_encoding.eq(ce.BaseNEncoder(base = base).fit_transform(X = x.sort_values()).drop('x_0', axis = 1).rename(lambda c: int(c[2:]) - 1, axis='columns')).all().all()\n",
    "\n",
    "base_n_encoding.columns = ['dim' + str(i) for i in range(base_n_encoding.shape[1], 0, -1)]\n",
    "show = pd.concat([x, ordinal_encoding, base_n, base_n_encoding], axis = 1)\n",
    "show.columns = [\n",
    "    ['x', 'ordinal_encoding', 'base_{}'.format(base)] + ['BaseNEncoding'] * base_n_encoding.shape[1],\n",
    "    [''] * 3 + list(base_n_encoding.columns)\n",
    "]\n",
    "show\n",
    "# Honestly, I don’t know any practical application of this type of encoding"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "               x                                           x_hashed  \\\n                                                                      \n0    2_Bachelors  dfdf62292a10a136ef6c334ce42a2b9678bfaca95082ca...   \n1  1_High-School  246ef3f20c0e981d07dd9403889eda024e8cda9a607444...   \n2          4_PhD  05696fc5341308e512fca84cee1462028e38e2121dc07b...   \n3      3_Masters  87cfcc5fbb3c7208a37a6b217aecae0fe3e363ecc6753a...   \n4  1_High-School  246ef3f20c0e981d07dd9403889eda024e8cda9a607444...   \n5    2_Bachelors  dfdf62292a10a136ef6c334ce42a2b9678bfaca95082ca...   \n\n                                        x_hashed_int x_hashed_int_remainder  \\\n                                                                              \n0  1012604496104437404713436958132099208170126968...                      0   \n1  1647929937606232701793386007505252070943301070...                      7   \n2  2447854595156119084567771247529450695955408508...                      2   \n3  6142938243831803099648826653448075878678926793...                      3   \n4  1647929937606232701793386007505252070943301070...                      7   \n5  1012604496104437404713436958132099208170126968...                      0   \n\n  HashingEncoding                                                     \n             dim0 dim1 dim2 dim3 dim4 dim5 dim6 dim7 dim8 dim9 dim10  \n0               1    0    0    0    0    0    0    0    0    0     0  \n1               0    0    0    0    0    0    0    1    0    0     0  \n2               0    0    1    0    0    0    0    0    0    0     0  \n3               0    0    0    1    0    0    0    0    0    0     0  \n4               0    0    0    0    0    0    0    1    0    0     0  \n5               1    0    0    0    0    0    0    0    0    0     0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>x</th>\n      <th>x_hashed</th>\n      <th>x_hashed_int</th>\n      <th>x_hashed_int_remainder</th>\n      <th colspan=\"11\" halign=\"left\">HashingEncoding</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>dim0</th>\n      <th>dim1</th>\n      <th>dim2</th>\n      <th>dim3</th>\n      <th>dim4</th>\n      <th>dim5</th>\n      <th>dim6</th>\n      <th>dim7</th>\n      <th>dim8</th>\n      <th>dim9</th>\n      <th>dim10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2_Bachelors</td>\n      <td>dfdf62292a10a136ef6c334ce42a2b9678bfaca95082ca...</td>\n      <td>1012604496104437404713436958132099208170126968...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>246ef3f20c0e981d07dd9403889eda024e8cda9a607444...</td>\n      <td>1647929937606232701793386007505252070943301070...</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4_PhD</td>\n      <td>05696fc5341308e512fca84cee1462028e38e2121dc07b...</td>\n      <td>2447854595156119084567771247529450695955408508...</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3_Masters</td>\n      <td>87cfcc5fbb3c7208a37a6b217aecae0fe3e363ecc6753a...</td>\n      <td>6142938243831803099648826653448075878678926793...</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1_High-School</td>\n      <td>246ef3f20c0e981d07dd9403889eda024e8cda9a607444...</td>\n      <td>1647929937606232701793386007505252070943301070...</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>dfdf62292a10a136ef6c334ce42a2b9678bfaca95082ca...</td>\n      <td>1012604496104437404713436958132099208170126968...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10. Hashing Encoder\n",
    "# In HashingEncoder, each original level is hashed, using some hashing\n",
    "# algorithm, such as SHA-256. Then, the outcome is converted to integer\n",
    "# and the module of that integer with respect to some (big) divisor is taken.\n",
    "# By doing so, we have mapped each original string to an integer between 1\n",
    "# and divisor-1. Lastly, the integer that has been obtained by this procedure\n",
    "# is one-hot encoded\n",
    "\n",
    "x = pd.Series(['2_Bachelors', '1_High-School', '4_PhD', '3_Masters', '1_High-School', '2_Bachelors'], name = 'x')\n",
    "\n",
    "def do_hash(string, output_dimension):\n",
    "    hasher = hashlib.new('sha256')\n",
    "    hasher.update(bytes(string, 'utf-8'))\n",
    "    string_hashed = hasher.hexdigest()\n",
    "    string_hashed_int = int(string_hashed, 16)\n",
    "    string_hashed_int_remainder = string_hashed_int % output_dimension\n",
    "    return string_hashed, string_hashed_int, string_hashed_int_remainder\n",
    "\n",
    "output_dimension = 11\n",
    "hashing = x.apply(\n",
    "    lambda string: pd.Series(do_hash(string, output_dimension),\n",
    "                             index=['x_hashed', 'x_hashed_int', 'x_hashed_int_remainder'])\n",
    ")\n",
    "hashing_encoding = hashing['x_hashed_int_remainder'].apply(\n",
    "    lambda rem: pd.Series(np.diag(np.ones(output_dimension))[rem])\n",
    ").astype(int)\n",
    "\n",
    "# ensure that our output coincides with the one from category_encoders\n",
    "assert hashing_encoding.eq(ce.HashingEncoder(hash_method = 'sha256', n_components = output_dimension).fit_transform(X = x).rename(lambda c: int(c[4:]), axis='columns')).all().all()\n",
    "\n",
    "hashing_encoding.columns = ['dim' + str(i) for i in range(hashing_encoding.shape[1])]\n",
    "show = pd.concat([x, hashing, hashing_encoding], axis = 1)\n",
    "show.columns = [\n",
    "    ['x', 'x_hashed', 'x_hashed_int', 'x_hashed_int_remainder'] + ['HashingEncoding'] * hashing_encoding.shape[1],\n",
    "    [''] * 4 + list(hashing_encoding.columns)\n",
    "]\n",
    "show\n",
    "\n",
    "# The fundamental property of hashing is that the resulting integer is\n",
    "# uniformly distributed. So, if you take a divisor big enough, it’s unlikely\n",
    "# that two different strings are mapped to the same integer. Why would that\n",
    "# be useful? Actually, this has a very practical application\n",
    "# called “hashing trick”.\n",
    "# Imagine that you want to make an email spam classifier using a\n",
    "# logistic regression. You could do that by one-hot-encoding all the words\n",
    "# contained in your dataset. The main downsides are that you would need to\n",
    "# store the mapping in a separate dictionary and your model dimensions would\n",
    "# change any time that new strings appear.\n",
    "# These issues may be easily overcome by using the hashing trick, because\n",
    "# by hashing the input, you don’t need a dictionary anymore and your\n",
    "# output dimension is fixed (it depends only on the divisor that you choose\n",
    "# initially). Moreover, for the properties of hashing, you are granted that\n",
    "# a new string will likely have a different encoding than the existing one"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "                x   y y_level_mean y_grand_mean TargetEncoding              \\\n                                                   smoothing=0 smoothing=1   \n0   1_High-School  35        36.50        52.27          36.50       40.74   \n1   1_High-School  38        36.50        52.27          36.50       40.74   \n2     2_Bachelors  49        50.25        52.27          50.25       50.35   \n3     2_Bachelors  45        50.25        52.27          50.25       50.35   \n4     2_Bachelors  52        50.25        52.27          50.25       50.35   \n5     2_Bachelors  55        50.25        52.27          50.25       50.35   \n6       3_Masters  63        59.00        52.27          59.00       58.20   \n7       3_Masters  47        59.00        52.27          59.00       58.20   \n8       3_Masters  67        59.00        52.27          59.00       58.20   \n9           4_PhD  51        62.00        52.27          62.00       59.38   \n10          4_PhD  73        62.00        52.27          62.00       59.38   \n\n                 \n   smoothing=10  \n0         43.99  \n1         43.99  \n2         51.11  \n3         51.11  \n4         51.11  \n5         51.11  \n6         55.97  \n7         55.97  \n8         55.97  \n9         57.38  \n10        57.38  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>y_level_mean</th>\n      <th>y_grand_mean</th>\n      <th colspan=\"3\" halign=\"left\">TargetEncoding</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>smoothing=0</th>\n      <th>smoothing=1</th>\n      <th>smoothing=10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1_High-School</td>\n      <td>35</td>\n      <td>36.50</td>\n      <td>52.27</td>\n      <td>36.50</td>\n      <td>40.74</td>\n      <td>43.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>38</td>\n      <td>36.50</td>\n      <td>52.27</td>\n      <td>36.50</td>\n      <td>40.74</td>\n      <td>43.99</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2_Bachelors</td>\n      <td>49</td>\n      <td>50.25</td>\n      <td>52.27</td>\n      <td>50.25</td>\n      <td>50.35</td>\n      <td>51.11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2_Bachelors</td>\n      <td>45</td>\n      <td>50.25</td>\n      <td>52.27</td>\n      <td>50.25</td>\n      <td>50.35</td>\n      <td>51.11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2_Bachelors</td>\n      <td>52</td>\n      <td>50.25</td>\n      <td>52.27</td>\n      <td>50.25</td>\n      <td>50.35</td>\n      <td>51.11</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>55</td>\n      <td>50.25</td>\n      <td>52.27</td>\n      <td>50.25</td>\n      <td>50.35</td>\n      <td>51.11</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3_Masters</td>\n      <td>63</td>\n      <td>59.00</td>\n      <td>52.27</td>\n      <td>59.00</td>\n      <td>58.20</td>\n      <td>55.97</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3_Masters</td>\n      <td>47</td>\n      <td>59.00</td>\n      <td>52.27</td>\n      <td>59.00</td>\n      <td>58.20</td>\n      <td>55.97</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3_Masters</td>\n      <td>67</td>\n      <td>59.00</td>\n      <td>52.27</td>\n      <td>59.00</td>\n      <td>58.20</td>\n      <td>55.97</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4_PhD</td>\n      <td>51</td>\n      <td>62.00</td>\n      <td>52.27</td>\n      <td>62.00</td>\n      <td>59.38</td>\n      <td>57.38</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4_PhD</td>\n      <td>73</td>\n      <td>62.00</td>\n      <td>52.27</td>\n      <td>62.00</td>\n      <td>59.38</td>\n      <td>57.38</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 11. Target Encoder\n",
    "# Suppose that you have two variables: one categorical (x) and one numeric (y).\n",
    "# Say that you want to transform x into a numeric variable. You may want to\n",
    "# employ the information “carried” by y.\n",
    "# An obvious idea is to take the mean of y for each level of x\n",
    "# This is reasonable, but there’s a big problem with this approach:\n",
    "# some groups may be too small or too variable to be reliable.\n",
    "# Many supervised encodings overcome this issue by choosing a middle way\n",
    "# between the group mean and the global mean of y:\n",
    "# enc_i = w_i * mean(y | x = i) + (1 - w_i) * mean(y)\n",
    "# where w_i is between 0 and 1, depending on how 'credible' is the group mean\n",
    "\n",
    "# The next three algorithms (TargetEncoder, MEstimateEncoder\n",
    "# and JamesSteinEncoder) differ based on how they define w_i.\n",
    "\n",
    "# In TargetEncoder, the weight depends on the group numerosity and\n",
    "# on a parameter called “smoothing”. When smoothing is 0, we rely solely\n",
    "# on group means. Then, as smoothing increases, the global mean weights\n",
    "# more and more, leading to a stronger regularization.\n",
    "\n",
    "x = pd.Series([\n",
    "    '1_High-School', '1_High-School', '2_Bachelors',\n",
    "    '2_Bachelors', '2_Bachelors', '2_Bachelors',\n",
    "    '3_Masters', '3_Masters', '3_Masters', '4_PhD', '4_PhD'\n",
    "    ], name = 'x')\n",
    "y = pd.Series([35, 38, 49, 45, 52, 55, 63, 47, 67, 51, 73], name = 'y')\n",
    "count_encoding = x.replace(x.value_counts().to_dict())\n",
    "\n",
    "y_grand_mean = y.mean()\n",
    "y_level_mean = x.replace(y.groupby(x).mean())\n",
    "smoothing = 1\n",
    "weight = 1 / (1 + np.exp(-(count_encoding - 1) / smoothing))\n",
    "target_encoding = y_level_mean * weight + y_grand_mean * (1- weight)\n",
    "\n",
    "\n",
    "# ensure that our output coincides with the one from category_encoders\n",
    "assert (target_encoding == ce.TargetEncoder(smoothing = smoothing).fit_transform(X = x, y = y).iloc[:, 0]).all()\n",
    "\n",
    "count_encoding = x.replace(y.groupby(x).count())\n",
    "y_grand_mean = x.apply(lambda l: y.mean())\n",
    "y_level_mean = x.replace(y.groupby(x).mean())\n",
    "target_encoding = dict()\n",
    "for smoothing in [0, 1, 10]:\n",
    "    weight = 1 / (1 + np.exp(-(count_encoding - 1) / smoothing))\n",
    "    target_encoding[smoothing] = (y_level_mean * weight + y_grand_mean * (1 - weight)).round(2)\n",
    "\n",
    "show = pd.concat([x, y, y_level_mean, y_grand_mean] + [target_encoding[i] for i in target_encoding.keys()], axis = 1)\n",
    "show.columns = [\n",
    "    ['x', 'y', 'y_level_mean', 'y_grand_mean'] + ['TargetEncoding'] * len(target_encoding),\n",
    "    [''] * 4 + ['smoothing={}'.format(sm) for sm in target_encoding.keys()]\n",
    "]\n",
    "show.round(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "                x   y CountEncoding y_level_mean y_grand_mean  \\\n                                                                \n0   1_High-School  35             2        36.50        52.27   \n1   1_High-School  38             2        36.50        52.27   \n2     2_Bachelors  49             4        50.25        52.27   \n3     2_Bachelors  45             4        50.25        52.27   \n4     2_Bachelors  52             4        50.25        52.27   \n5     2_Bachelors  55             4        50.25        52.27   \n6       3_Masters  63             3        59.00        52.27   \n7       3_Masters  47             3        59.00        52.27   \n8       3_Masters  67             3        59.00        52.27   \n9           4_PhD  51             2        62.00        52.27   \n10          4_PhD  73             2        62.00        52.27   \n\n   MEstimateEncoding                \n                 m=0    m=1   m=10  \n0              36.50  41.76  49.64  \n1              36.50  41.76  49.64  \n2              50.25  50.65  51.69  \n3              50.25  50.65  51.69  \n4              50.25  50.65  51.69  \n5              50.25  50.65  51.69  \n6              59.00  57.32  53.83  \n7              59.00  57.32  53.83  \n8              59.00  57.32  53.83  \n9              62.00  58.76  53.89  \n10             62.00  58.76  53.89  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>CountEncoding</th>\n      <th>y_level_mean</th>\n      <th>y_grand_mean</th>\n      <th colspan=\"3\" halign=\"left\">MEstimateEncoding</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th>m=0</th>\n      <th>m=1</th>\n      <th>m=10</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1_High-School</td>\n      <td>35</td>\n      <td>2</td>\n      <td>36.50</td>\n      <td>52.27</td>\n      <td>36.50</td>\n      <td>41.76</td>\n      <td>49.64</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>38</td>\n      <td>2</td>\n      <td>36.50</td>\n      <td>52.27</td>\n      <td>36.50</td>\n      <td>41.76</td>\n      <td>49.64</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2_Bachelors</td>\n      <td>49</td>\n      <td>4</td>\n      <td>50.25</td>\n      <td>52.27</td>\n      <td>50.25</td>\n      <td>50.65</td>\n      <td>51.69</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2_Bachelors</td>\n      <td>45</td>\n      <td>4</td>\n      <td>50.25</td>\n      <td>52.27</td>\n      <td>50.25</td>\n      <td>50.65</td>\n      <td>51.69</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2_Bachelors</td>\n      <td>52</td>\n      <td>4</td>\n      <td>50.25</td>\n      <td>52.27</td>\n      <td>50.25</td>\n      <td>50.65</td>\n      <td>51.69</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>55</td>\n      <td>4</td>\n      <td>50.25</td>\n      <td>52.27</td>\n      <td>50.25</td>\n      <td>50.65</td>\n      <td>51.69</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3_Masters</td>\n      <td>63</td>\n      <td>3</td>\n      <td>59.00</td>\n      <td>52.27</td>\n      <td>59.00</td>\n      <td>57.32</td>\n      <td>53.83</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3_Masters</td>\n      <td>47</td>\n      <td>3</td>\n      <td>59.00</td>\n      <td>52.27</td>\n      <td>59.00</td>\n      <td>57.32</td>\n      <td>53.83</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3_Masters</td>\n      <td>67</td>\n      <td>3</td>\n      <td>59.00</td>\n      <td>52.27</td>\n      <td>59.00</td>\n      <td>57.32</td>\n      <td>53.83</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4_PhD</td>\n      <td>51</td>\n      <td>2</td>\n      <td>62.00</td>\n      <td>52.27</td>\n      <td>62.00</td>\n      <td>58.76</td>\n      <td>53.89</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4_PhD</td>\n      <td>73</td>\n      <td>2</td>\n      <td>62.00</td>\n      <td>52.27</td>\n      <td>62.00</td>\n      <td>58.76</td>\n      <td>53.89</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 12. M Estimate Encoder\n",
    "# MEstimateEncoder resembles TargetEncoder, but w_i depends on a parameter\n",
    "# called “m”, which sets how much the global mean should weight in\n",
    "# absolute terms. m is easy to understand because it can be considered as\n",
    "# a number of observations: if the level has exactly m observations,\n",
    "# then the level mean and the overall mean weight the same.\n",
    "\n",
    "x = pd.Series([\n",
    "    '1_High-School', '1_High-School', '2_Bachelors',\n",
    "    '2_Bachelors', '2_Bachelors', '2_Bachelors',\n",
    "    '3_Masters', '3_Masters', '3_Masters', '4_PhD', '4_PhD'\n",
    "    ], name = 'x')\n",
    "y = pd.Series([35, 38, 49, 45, 52, 55, 63, 47, 67, 51, 73], name = 'y')\n",
    "\n",
    "m = 0\n",
    "count_encoding = x.replace(y.groupby(x).count())\n",
    "y_mean = y.mean()\n",
    "y_level_mean = x.replace(y.groupby(x).mean())\n",
    "weight = count_encoding / (count_encoding + m)\n",
    "m_estimate_encoding = y_level_mean * weight + y_mean * (1 - weight)\n",
    "\n",
    "assert (m_estimate_encoding == ce.MEstimateEncoder(m = m).fit_transform(X = x, y = y).iloc[:, 0]).all()\n",
    "\n",
    "m_estimate_encoding = dict()\n",
    "\n",
    "for m in [0, 1, 10]:\n",
    "    m_estimate_encoding[m] = ((y_level_mean * count_encoding + y_grand_mean * m) / (count_encoding + m)).round(2)\n",
    "\n",
    "# ensure that our output coincides with the one from category_encoders\n",
    "for m, te in m_estimate_encoding.items():\n",
    "    assert (te == ce.MEstimateEncoder(m = m).fit_transform(X = x, y = y).iloc[:, 0].round(2)).all()\n",
    "\n",
    "show = pd.concat([x, y, count_encoding, y_level_mean, y_grand_mean] + [m_estimate_encoding[i] for i in m_estimate_encoding.keys()], axis = 1)\n",
    "show.columns = [\n",
    "    ['x', 'y', 'CountEncoding', 'y_level_mean', 'y_grand_mean'] + ['MEstimateEncoding'] * len(m_estimate_encoding),\n",
    "    [''] * 5 + ['m={}'.format(m) for m in m_estimate_encoding.keys()]\n",
    "]\n",
    "show.round(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "                x   y  y_level_mean  y_level_var  y_mean   y_var  weight  \\\n0   1_High-School  35         36.50         4.50   52.27  136.42    0.99   \n1   1_High-School  38         36.50         4.50   52.27  136.42    0.99   \n2     2_Bachelors  49         50.25        18.25   52.27  136.42    0.96   \n3     2_Bachelors  45         50.25        18.25   52.27  136.42    0.96   \n4     2_Bachelors  52         50.25        18.25   52.27  136.42    0.96   \n5     2_Bachelors  55         50.25        18.25   52.27  136.42    0.96   \n6       3_Masters  63         59.00       112.00   52.27  136.42    0.85   \n7       3_Masters  47         59.00       112.00   52.27  136.42    0.85   \n8       3_Masters  67         59.00       112.00   52.27  136.42    0.85   \n9           4_PhD  51         62.00       242.00   52.27  136.42    0.79   \n10          4_PhD  73         62.00       242.00   52.27  136.42    0.79   \n\n    JamesSteinEncoding  \n0                36.67  \n1                36.67  \n2                50.33  \n3                50.33  \n4                50.33  \n5                50.33  \n6                57.99  \n7                57.99  \n8                57.99  \n9                59.93  \n10               59.93  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>y_level_mean</th>\n      <th>y_level_var</th>\n      <th>y_mean</th>\n      <th>y_var</th>\n      <th>weight</th>\n      <th>JamesSteinEncoding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1_High-School</td>\n      <td>35</td>\n      <td>36.50</td>\n      <td>4.50</td>\n      <td>52.27</td>\n      <td>136.42</td>\n      <td>0.99</td>\n      <td>36.67</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>38</td>\n      <td>36.50</td>\n      <td>4.50</td>\n      <td>52.27</td>\n      <td>136.42</td>\n      <td>0.99</td>\n      <td>36.67</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2_Bachelors</td>\n      <td>49</td>\n      <td>50.25</td>\n      <td>18.25</td>\n      <td>52.27</td>\n      <td>136.42</td>\n      <td>0.96</td>\n      <td>50.33</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2_Bachelors</td>\n      <td>45</td>\n      <td>50.25</td>\n      <td>18.25</td>\n      <td>52.27</td>\n      <td>136.42</td>\n      <td>0.96</td>\n      <td>50.33</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2_Bachelors</td>\n      <td>52</td>\n      <td>50.25</td>\n      <td>18.25</td>\n      <td>52.27</td>\n      <td>136.42</td>\n      <td>0.96</td>\n      <td>50.33</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>55</td>\n      <td>50.25</td>\n      <td>18.25</td>\n      <td>52.27</td>\n      <td>136.42</td>\n      <td>0.96</td>\n      <td>50.33</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3_Masters</td>\n      <td>63</td>\n      <td>59.00</td>\n      <td>112.00</td>\n      <td>52.27</td>\n      <td>136.42</td>\n      <td>0.85</td>\n      <td>57.99</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3_Masters</td>\n      <td>47</td>\n      <td>59.00</td>\n      <td>112.00</td>\n      <td>52.27</td>\n      <td>136.42</td>\n      <td>0.85</td>\n      <td>57.99</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3_Masters</td>\n      <td>67</td>\n      <td>59.00</td>\n      <td>112.00</td>\n      <td>52.27</td>\n      <td>136.42</td>\n      <td>0.85</td>\n      <td>57.99</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4_PhD</td>\n      <td>51</td>\n      <td>62.00</td>\n      <td>242.00</td>\n      <td>52.27</td>\n      <td>136.42</td>\n      <td>0.79</td>\n      <td>59.93</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4_PhD</td>\n      <td>73</td>\n      <td>62.00</td>\n      <td>242.00</td>\n      <td>52.27</td>\n      <td>136.42</td>\n      <td>0.79</td>\n      <td>59.93</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 13. James-Stein Encoding\n",
    "# TargetEncoder and MEstimateEncoder depend both on the group numerosity\n",
    "# and on the value of a parameter (respectively smoothing and m) set by\n",
    "# the user. This is not convenient, because setting these weights is a\n",
    "# manual task.\n",
    "# A natural question is the following: is there a way to set an optimal w_i,\n",
    "# without the need of any human intervention? The JamesSteinEncoder tries\n",
    "# to do so in a way that is statistically grounded.\n",
    "\n",
    "\n",
    "x = pd.Series([\n",
    "    '1_High-School', '1_High-School', '2_Bachelors',\n",
    "    '2_Bachelors', '2_Bachelors', '2_Bachelors',\n",
    "    '3_Masters', '3_Masters', '3_Masters', '4_PhD', '4_PhD'\n",
    "    ], name = 'x')\n",
    "y = pd.Series([35, 38, 49, 45, 52, 55, 63, 47, 67, 51, 73], name = 'y')\n",
    "\n",
    "y_level_mean = x.replace(y.groupby(x).mean())\n",
    "y_level_var = x.replace(y.groupby(x).var())\n",
    "y_var = y.var()\n",
    "y_mean = y.mean()\n",
    "weight = 1 - (y_level_var/ (y_var + y_level_var) * (len(set(x)) - 3) / (len(set(x)) -1)).clip(lower=0, upper=1)\n",
    "james_stein_encoding = y_level_mean * weight + y_mean * (1 - weight)\n",
    "\n",
    "# ensure that our output coincides with the one from category_encoders\n",
    "assert (james_stein_encoding == ce.JamesSteinEncoder().fit_transform(X = x, y = y).iloc[:, 0]).all()\n",
    "\n",
    "show = pd.concat([x, y, y_level_mean, y_level_var, pd.Series(y.mean(), index = x.index), pd.Series(y.var(), index = x.index), weight, james_stein_encoding], axis = 1)\n",
    "show.columns = ['x', 'y', 'y_level_mean', 'y_level_var', 'y_mean', 'y_var', 'weight', 'JamesSteinEncoding']\n",
    "show.round(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "                x   y  intercept  random_effect  GLMMEncoding\n0   1_High-School  35      52.05         -10.82         41.24\n1   1_High-School  38      52.05         -10.82         41.24\n2     2_Bachelors  49      52.05          -1.48         50.57\n3     2_Bachelors  45      52.05          -1.48         50.57\n4     2_Bachelors  52      52.05          -1.48         50.57\n5     2_Bachelors  55      52.05          -1.48         50.57\n6       3_Masters  63      52.05           5.38         57.43\n7       3_Masters  47      52.05           5.38         57.43\n8       3_Masters  67      52.05           5.38         57.43\n9           4_PhD  51      52.05           6.92         58.97\n10          4_PhD  73      52.05           6.92         58.97",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>intercept</th>\n      <th>random_effect</th>\n      <th>GLMMEncoding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1_High-School</td>\n      <td>35</td>\n      <td>52.05</td>\n      <td>-10.82</td>\n      <td>41.24</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>38</td>\n      <td>52.05</td>\n      <td>-10.82</td>\n      <td>41.24</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2_Bachelors</td>\n      <td>49</td>\n      <td>52.05</td>\n      <td>-1.48</td>\n      <td>50.57</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2_Bachelors</td>\n      <td>45</td>\n      <td>52.05</td>\n      <td>-1.48</td>\n      <td>50.57</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2_Bachelors</td>\n      <td>52</td>\n      <td>52.05</td>\n      <td>-1.48</td>\n      <td>50.57</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>55</td>\n      <td>52.05</td>\n      <td>-1.48</td>\n      <td>50.57</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3_Masters</td>\n      <td>63</td>\n      <td>52.05</td>\n      <td>5.38</td>\n      <td>57.43</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3_Masters</td>\n      <td>47</td>\n      <td>52.05</td>\n      <td>5.38</td>\n      <td>57.43</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3_Masters</td>\n      <td>67</td>\n      <td>52.05</td>\n      <td>5.38</td>\n      <td>57.43</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4_PhD</td>\n      <td>51</td>\n      <td>52.05</td>\n      <td>6.92</td>\n      <td>58.97</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4_PhD</td>\n      <td>73</td>\n      <td>52.05</td>\n      <td>6.92</td>\n      <td>58.97</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 14. GLMMEncoder\n",
    "# GLMMEncoder fits a Linear Mixed Effect Model on y.\n",
    "# This approach exploits the fact that Linear Mixed Effect Models\n",
    "# are designed precisely for handling homogeneous groups of observations.\n",
    "# Thus, the idea is to fit a model with no regressors (only the intercept)\n",
    "# and to use the levels as groups.\n",
    "# Then, the output is simply the sum of the intercept\n",
    "# and the random effect of the group\n",
    "\n",
    "x = pd.Series([\n",
    "    '1_High-School', '1_High-School', '2_Bachelors',\n",
    "    '2_Bachelors', '2_Bachelors', '2_Bachelors',\n",
    "    '3_Masters', '3_Masters', '3_Masters', '4_PhD', '4_PhD'\n",
    "    ], name = 'x')\n",
    "y = pd.Series([35, 38, 49, 45, 52, 55, 63, 47, 67, 51, 73], name = 'y')\n",
    "\n",
    "model = smf.mixedlm(formula = 'y ~ 1', data = y.to_frame(), groups = x).fit()\n",
    "intercept = model.params['Intercept']\n",
    "random_effect = x.replace({k: float(v) for k, v in model.random_effects.items()})\n",
    "glmm_encoding = intercept + random_effect\n",
    "\n",
    "# in this case, category_encoders coincides only with the random_effect, not with the glmm_encoding\n",
    "assert (random_effect == ce.GLMMEncoder().fit_transform(X = x, y = y).iloc[:, 0]).all()\n",
    "\n",
    "show = pd.concat([x, y, pd.Series(intercept, index = x.index), random_effect, glmm_encoding], axis = 1)\n",
    "show.columns = ['x', 'y', 'intercept', 'random_effect', 'GLMMEncoding']\n",
    "show.round(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "                x  y  y_level_ones  y_level_zeros  y_ones  y_zeros  nominator  \\\n0   1_High-School  1             1              1       4        7       0.25   \n1   1_High-School  0             1              1       4        7       0.25   \n2     2_Bachelors  0             1              3       4        7       0.25   \n3     2_Bachelors  0             1              3       4        7       0.25   \n4     2_Bachelors  1             1              3       4        7       0.25   \n5     2_Bachelors  0             1              3       4        7       0.25   \n6       3_Masters  0             1              2       4        7       0.25   \n7       3_Masters  1             1              2       4        7       0.25   \n8       3_Masters  0             1              2       4        7       0.25   \n9           4_PhD  0             1              1       4        7       0.25   \n10          4_PhD  1             1              1       4        7       0.25   \n\n    denominator  WOEEncoding  \n0      0.142857     0.559616  \n1      0.142857     0.559616  \n2      0.428571    -0.538997  \n3      0.428571    -0.538997  \n4      0.428571    -0.538997  \n5      0.428571    -0.538997  \n6      0.285714    -0.133531  \n7      0.285714    -0.133531  \n8      0.285714    -0.133531  \n9      0.142857     0.559616  \n10     0.142857     0.559616  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>y_level_ones</th>\n      <th>y_level_zeros</th>\n      <th>y_ones</th>\n      <th>y_zeros</th>\n      <th>nominator</th>\n      <th>denominator</th>\n      <th>WOEEncoding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1_High-School</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0.25</td>\n      <td>0.142857</td>\n      <td>0.559616</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0.25</td>\n      <td>0.142857</td>\n      <td>0.559616</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2_Bachelors</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0.25</td>\n      <td>0.428571</td>\n      <td>-0.538997</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2_Bachelors</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0.25</td>\n      <td>0.428571</td>\n      <td>-0.538997</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2_Bachelors</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0.25</td>\n      <td>0.428571</td>\n      <td>-0.538997</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>0</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0.25</td>\n      <td>0.428571</td>\n      <td>-0.538997</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3_Masters</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0.25</td>\n      <td>0.285714</td>\n      <td>-0.133531</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3_Masters</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0.25</td>\n      <td>0.285714</td>\n      <td>-0.133531</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3_Masters</td>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0.25</td>\n      <td>0.285714</td>\n      <td>-0.133531</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4_PhD</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0.25</td>\n      <td>0.142857</td>\n      <td>0.559616</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4_PhD</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>7</td>\n      <td>0.25</td>\n      <td>0.142857</td>\n      <td>0.559616</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 15. WOEEncoder\n",
    "# WOEEncoder (which stands for “Weight of Evidence” Encoder) can be employed\n",
    "# only for binary target variables, i.e. target variables whose levels are 0/1\n",
    "\n",
    "# The idea behind Weight of Evidence is that you have two distributions:\n",
    "# - the distribution of 1s (# of 1s in each group / # of 1s in all y)\n",
    "# - the distribution of 0s (# of 0s in each group / # of 0s in all y)\n",
    "\n",
    "# The heart of the algorithm is dividing the distribution of 1s by the\n",
    "# distribution of 0s (for each group). Of course, the higher this value,\n",
    "# the more confident we are that the group is “skewed” towards 1s,\n",
    "# and viceversa. Then, the logarithm of this value is taken.\n",
    "\n",
    "x = pd.Series([\n",
    "    '1_High-School', '1_High-School', '2_Bachelors',\n",
    "    '2_Bachelors', '2_Bachelors', '2_Bachelors',\n",
    "    '3_Masters', '3_Masters', '3_Masters', '4_PhD', '4_PhD'\n",
    "    ], name = 'x')\n",
    "y = pd.Series([1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1], name = 'y')\n",
    "\n",
    "y_level_ones = x.replace(y.groupby(x).apply(lambda l: (l==1).sum()))\n",
    "y_level_zeros = x.replace(y.groupby(x).apply(lambda l: (l==0).sum()))\n",
    "y_ones = (y==1).sum()\n",
    "y_zeros = (y==0).sum()\n",
    "nominator = y_level_ones / y_ones\n",
    "denominator = y_level_zeros / y_zeros\n",
    "woe_encoder = np.log(nominator/denominator)\n",
    "\n",
    "assert (woe_encoder == ce.WOEEncoder(regularization = 0).fit_transform(X = x, y = y).iloc[:, 0]).all()\n",
    "\n",
    "show = pd.concat([x, y, y_level_ones, y_level_zeros, pd.Series(y_ones, index = x.index), pd.Series(y_zeros, index = x.index), nominator, denominator, woe_encoder], axis = 1)\n",
    "show.columns = ['x', 'y', 'y_level_ones', 'y_level_zeros', 'y_ones', 'y_zeros','nominator', 'denominator', 'WOEEncoding']\n",
    "show\n",
    "\n",
    "# As you can see, due to the presence of a logarithm in the formula,\n",
    "# the output is not not directly interpretable. However, it works pretty\n",
    "# well as a preprocessing step for machine learning."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "                x   y y_level_except_self  LeaveOneOutEncoding\n0   1_High-School  35                [38]                38.00\n1   1_High-School  38                [35]                35.00\n2     2_Bachelors  49        [45, 52, 55]                50.67\n3     2_Bachelors  45        [49, 52, 55]                52.00\n4     2_Bachelors  52        [49, 45, 55]                49.67\n5     2_Bachelors  55        [49, 45, 52]                48.67\n6       3_Masters  63            [47, 67]                57.00\n7       3_Masters  47            [63, 67]                65.00\n8       3_Masters  67            [63, 47]                55.00\n9           4_PhD  51                [73]                73.00\n10          4_PhD  73                [51]                51.00",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>y_level_except_self</th>\n      <th>LeaveOneOutEncoding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1_High-School</td>\n      <td>35</td>\n      <td>[38]</td>\n      <td>38.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>38</td>\n      <td>[35]</td>\n      <td>35.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2_Bachelors</td>\n      <td>49</td>\n      <td>[45, 52, 55]</td>\n      <td>50.67</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2_Bachelors</td>\n      <td>45</td>\n      <td>[49, 52, 55]</td>\n      <td>52.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2_Bachelors</td>\n      <td>52</td>\n      <td>[49, 45, 55]</td>\n      <td>49.67</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>55</td>\n      <td>[49, 45, 52]</td>\n      <td>48.67</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3_Masters</td>\n      <td>63</td>\n      <td>[47, 67]</td>\n      <td>57.00</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3_Masters</td>\n      <td>47</td>\n      <td>[63, 67]</td>\n      <td>65.00</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3_Masters</td>\n      <td>67</td>\n      <td>[63, 47]</td>\n      <td>55.00</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4_PhD</td>\n      <td>51</td>\n      <td>[73]</td>\n      <td>73.00</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4_PhD</td>\n      <td>73</td>\n      <td>[51]</td>\n      <td>51.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 16. Leave One Out Encoder\n",
    "\n",
    "# However, if you plan to use the encoding as input for a predictive model\n",
    "# (for example a gradient boosting), this could be a problem. In fact,\n",
    "# suppose that you use TargetEncoder. This would imply that you are\n",
    "# introducing information about y_train inside X_train, which could lead\n",
    "# to a serious risk of overfitting\n",
    "\n",
    "# The point is: how to maintain a supervised encoding, while limiting the\n",
    "# risk of overfitting? LeaveOneOutEncoder offers a brilliant solution.\n",
    "# It does a vanilla target encoding but, for each row, it does not consider\n",
    "# the value of y observed for that row. In this way, it avoids row-wise leakage.\n",
    "\n",
    "x = pd.Series([\n",
    "    '1_High-School', '1_High-School', '2_Bachelors',\n",
    "    '2_Bachelors', '2_Bachelors', '2_Bachelors',\n",
    "    '3_Masters', '3_Masters', '3_Masters', '4_PhD', '4_PhD'\n",
    "    ], name = 'x')\n",
    "y = pd.Series([35, 38, 49, 45, 52, 55, 63, 47, 67, 51, 73], name = 'y')\n",
    "\n",
    "y_level_except_self = x.to_frame().apply(lambda row: y[x == row['x']].drop(row.name).to_list(), axis = 1)\n",
    "# just the mean\n",
    "leave_one_out_encoding = y_level_except_self.apply(np.mean)\n",
    "\n",
    "assert (leave_one_out_encoding == ce.LeaveOneOutEncoder().fit_transform(X = x, y = y).iloc[:, 0]).all()\n",
    "\n",
    "show = pd.concat([x, y, y_level_except_self, leave_one_out_encoding], axis = 1)\n",
    "show.columns = ['x', 'y', 'y_level_except_self', 'LeaveOneOutEncoding']\n",
    "show['LeaveOneOutEncoding'] = show['LeaveOneOutEncoding'].round(2)\n",
    "show"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "                x   y  y_mean y_level_before_self  CatBoostEncoding\n0   1_High-School  35   52.27                  []             52.27\n1   1_High-School  38   52.27                [35]             43.64\n2     2_Bachelors  49   52.27                  []             52.27\n3     2_Bachelors  45   52.27                [49]             50.64\n4     2_Bachelors  52   52.27            [49, 45]             48.76\n5     2_Bachelors  55   52.27        [49, 45, 52]             49.57\n6       3_Masters  63   52.27                  []             52.27\n7       3_Masters  47   52.27                [63]             57.64\n8       3_Masters  67   52.27            [63, 47]             54.09\n9           4_PhD  51   52.27                  []             52.27\n10          4_PhD  73   52.27                [51]             51.64",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x</th>\n      <th>y</th>\n      <th>y_mean</th>\n      <th>y_level_before_self</th>\n      <th>CatBoostEncoding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1_High-School</td>\n      <td>35</td>\n      <td>52.27</td>\n      <td>[]</td>\n      <td>52.27</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1_High-School</td>\n      <td>38</td>\n      <td>52.27</td>\n      <td>[35]</td>\n      <td>43.64</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2_Bachelors</td>\n      <td>49</td>\n      <td>52.27</td>\n      <td>[]</td>\n      <td>52.27</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2_Bachelors</td>\n      <td>45</td>\n      <td>52.27</td>\n      <td>[49]</td>\n      <td>50.64</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2_Bachelors</td>\n      <td>52</td>\n      <td>52.27</td>\n      <td>[49, 45]</td>\n      <td>48.76</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>2_Bachelors</td>\n      <td>55</td>\n      <td>52.27</td>\n      <td>[49, 45, 52]</td>\n      <td>49.57</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>3_Masters</td>\n      <td>63</td>\n      <td>52.27</td>\n      <td>[]</td>\n      <td>52.27</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>3_Masters</td>\n      <td>47</td>\n      <td>52.27</td>\n      <td>[63]</td>\n      <td>57.64</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>3_Masters</td>\n      <td>67</td>\n      <td>52.27</td>\n      <td>[63, 47]</td>\n      <td>54.09</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>4_PhD</td>\n      <td>51</td>\n      <td>52.27</td>\n      <td>[]</td>\n      <td>52.27</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>4_PhD</td>\n      <td>73</td>\n      <td>52.27</td>\n      <td>[51]</td>\n      <td>51.64</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 17. CatBoostEncoder\n",
    "# CatBoost is a gradient boosting algorithm (like XGBoost or LightGBM) that\n",
    "# has shown to work extremely well in a wide range of problems.\n",
    "# The encoding algorithm is described in detail here (our implementation is\n",
    "# a little simplified, but it’s good for grasping the concept).\n",
    "# CatboostEncoder works basically like LeaveOneOutEncoder,\n",
    "# but following an on-line approach.\n",
    "# But how to simulate an on-line behaviour in an off-line setting?\n",
    "# Imagine that you have a table. Then, take a row somewhere in the middle\n",
    "# of the table. What CatBoost does is pretending that the rows above the\n",
    "# current row have been observed previously in time, while the rows below\n",
    "# have yet to be observed (i.e. will be observed in the future). Then,\n",
    "# the algorithm does a leave-one-out encoding, but\n",
    "# based only on the rows already observed.\n",
    "\n",
    "x = pd.Series([\n",
    "    '1_High-School', '1_High-School', '2_Bachelors',\n",
    "    '2_Bachelors', '2_Bachelors', '2_Bachelors',\n",
    "    '3_Masters', '3_Masters', '3_Masters', '4_PhD', '4_PhD'\n",
    "    ], name = 'x')\n",
    "y = pd.Series([35, 38, 49, 45, 52, 55, 63, 47, 67, 51, 73], name = 'y')\n",
    "\n",
    "a = 1\n",
    "y_mean = y.mean()\n",
    "y_level_before_self = x.to_frame().apply(lambda row: y[(x == row['x']) & (y.index < row.name)].to_list(), axis = 1)\n",
    "catboost_encoding = y_level_before_self.apply(lambda ylbs: (sum(ylbs) + y_mean * a) / (len(ylbs) + a))\n",
    "\n",
    "assert (catboost_encoding == ce.CatBoostEncoder().fit_transform(X = x, y = y).iloc[:, 0]).all()\n",
    "\n",
    "show = pd.concat([x, y, pd.Series(y.mean(), index = x.index), y_level_before_self, catboost_encoding], axis = 1)\n",
    "show.columns = ['x', 'y', 'y_mean', 'y_level_before_self', 'CatBoostEncoding']\n",
    "show.round(2)\n",
    "\n",
    "# This may seem absurd. Why throwing away some information that could be useful?\n",
    "# You can see it simply as more extreme attempt of randomizing the output\n",
    "# (i.e. reducing overfitting)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
